---
title: "PROYECTO 1 ST"
format: html
editor: visual
---

# Series Temporales: Proyecto B1

```{r, echo=FALSE, include=FALSE}
#Librerías
library(tsibble)
library(dplyr)
library(lubridate)
library(fpp3)
library(tidyverse)
library(leaflet)
library(zoo)
library(fable)
library(imputeTS)
library(ggplot2)
library(tidyr)
library(stringr)
library(patchwork)
library(feasts)
library(knitr)

ruta<-"maate_concentracionso2_2021diciembre.csv"
```

```{r, echo=FALSE, warning=FALSE}
datos_so2 <- read.csv(ruta, sep = ";")
head(datos_so2)
datos_so2 <- datos_so2 |>  mutate(FECHA=dmy(paste(DIA, MES, ANIO)))

so2_diario <- datos_so2 |> 
  mutate(SO2 = as.numeric(SO2)) 


```

Tomaremos como nuestro índice temporal a la variable *FECHA.*

Ahora, el estudio se realizará en la provincia de Pichincha, entonces, las series temporales consideradas se basarán en cada estación de cada cantón de la ciudad de Quito. Como primera instancia, se realizará un análisis de características de seis estaciones de interés; a saber, Belisario, Carapungo, Cotocollao, Tumbaco, (las dos que faltan). En conjunto, estas estaciones muestran un gran contraste en la tipología de exposición y las fuentes de emisión, puesto que algunas de ellas enfrentan diariamente una exposición y emisión alta de SO2 por la presencia de actividades humanas a comparación de otras.

Borrar 2

```{r warning=FALSE, include=FALSE}
vector_estaciones <- c("Belisario", "Carapungo", "Cotocollao", "Tumbaco","Los Chillos","Guamani")

so2_ts <- so2_diario |> 
    filter(!is.na(SO2)) |> 
    filter(PROV == "Pichincha", ESTACION %in% vector_estaciones) |> 
    select(FECHA, ESTACION, SO2) |> 
    as_tsibble(index = FECHA, key = ESTACION) |> 
    fill_gaps() |> 
    mutate(SO2 = imputeTS::na_seadec(SO2, algorithm = "interpolation", 
                                     find_frequency = TRUE))

```

```{r, echo=FALSE}
serie_estaciones <- function(so2_diario, vector_estaciones) {
  
  so2_por_estaciones <- list()
  for(i in 1:length(vector_estaciones)){
    so2_por_estaciones[[i]] <- so2_ts |> 
      filter(ESTACION == vector_estaciones[i])
  }
  
  so2_por_estaciones
}

serie <- serie_estaciones(so2_diario, vector_estaciones)

```

Con la frecuencia diaria, pues, el SO2 al ser una sustancia muy volatil, es de interés saber los días que se alcanzan los máximos durante el año. Además que el SO2 suele estar ligado a la actividad humana, entonces, la medición diaria del SO2 tiene la capacidad de mostrar patrones cruciales. (REFERENCIA)

### Diversidad de las series de interés

#### Tendencia

```{r, echo=FALSE}

so2_ts |> 
  autoplot(SO2) +
  labs(title = "Estaciones", x="Tiempo") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")

```

#### Estacionalidad

```{r, echo=FALSE, warning=FALSE}

so2_ts |> 
  gg_season(SO2, labels="both") +
  labs(y="SO2 HG/m^3", x = "Tiempo",
       title = "Cantidad de SO2 en el aire por estaciones")

```

En el gráfico anterior se muestra que los primeros y últimos días de cada año, se da un efecto descendiente del SO2 en el aire, un patrón que como se explicó, se lo localiza por una frecuencia diaria.

#### Descomposición

El siguiente objetivo es ver el comportamiento de cada componente de la descomposición de ambas series.

```{r, echo=FALSE}
so2_ts |> 
  model(stl=STL(SO2)) |> 
  components() |> 
  autoplot() +
  labs(title = "Descomposición STL", x="Tiempo")
```

#### Estacionaridad

##### ACF

```{r, echo=FALSE}

so2_ts |> 
  ACF(SO2, lag_max = 200) |> 
  autoplot() + 
  labs(title = "ACF de cantidad de SO2 por estación") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")

```

(MODIFICAR) Los gráficos de la ACF, muestran que existe auto-correlación con lags pasados. Como por ejemplo el caso de Belisario, posee una alta auto-correlación hasta un lag cercano a 200, a diferencia de la cantidad de SO2 en Carapungo, que muestra una correlación más fuerte con los lag cercanos a 3.

Podemos ver en la siguiente tabla de valores del ACF para las dos series.

```{r, echo=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(gt)

acf_resultados_completos <- so2_ts |> 
  ACF(SO2, lag_max = 200) |> 
  as_tibble()

# Primero, preparar los datos en formato wide
tabla_wide <- acf_resultados_completos |>
  mutate(lag_num = as.numeric(gsub("D", "", lag))) |>
  # Filtrar los primeros 10 lags
  filter(lag_num <= 10) |>
  select(-lag_num) |> 
  # Convertir a formato wide (estaciones como filas, lags como columnas)
  pivot_wider(
    names_from = lag, 
    values_from = acf
  )

# Crear la tabla GT
tabla_ACF <- gt(tabla_wide) |>
  tab_header(
    title = "SO2 - Valores ACF por Lag"
  ) |>
  fmt_number(
    columns = -ESTACION,  # Aplicar a todas las columnas excepto "Estación"
    decimals = 4
  )

# Mostrar la tabla
tabla_ACF
```

Pero, es posible obtener un mejor acercamiento a la dependencia de la serie con los LAGS, pero primero se debe verificar si las series son Estacionarias o sino convertirlas con alguna transformación.

###### Método del ROLLMEAN

```{r, echo=FALSE, warning=FALSE}
so2_ts |> 
  mutate(mm=rollmean(SO2, k=5, fill = NA)) |> 
  autoplot(SO2) + 
  geom_line(aes(y=mm), colour="#D55E00") +
  labs(title = "Cantidad de SO2 por estación y la media puntual a lo largo del tiempo") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none") +
  guides(color = "none") +
  scale_color_manual(values = rep("black", length(vector_estaciones)))
```

A simple vista, parecen ser ambas series no estacionarias, pues, en los años del 2005 al 2006, las medias presentan picos muy altos, además que existe también una homocedasticidad.

Probemos el Test de KPSS para determinar si son o no estacionarias:

```{r, echo=FALSE}
test_kpss_todos <- so2_ts |> 
  features(SO2, unitroot_kpss)

tabla_kpss <- test_kpss_todos |> 
  filter(ESTACION %in% vector_estaciones)

kable(
  tabla_kpss,
  caption = "Resultados de la Prueba KPSS", 
  col.names = c("Fuente", "Estadístico", "Valor P"),
  digits = 4
)                                 
```

En todos los casos, por el test KPSS, se rechaza la idea que las series sean estacionarias pues, el *p-value* es menor o igual a 0.01, a excepsión de Guamani, que resulta ser estacionaria.

Entonces para ver realmente alguna dependencia de las series con algún LAG, por medio del PACF (además de luego poder aplicar métodos de modelado) , necesitamos que las series sean estacionarias. La forma más sencilla podría ser una simple diferenciación de orden m, para ellos KPSS, otorga el orden de diferenciación

```{r, echo=FALSE}

ordenes_diff <- so2_ts |> 
  features(SO2, unitroot_ndiffs)

tabla_ordenes <- ordenes_diff |> 
  filter(ESTACION %in% vector_estaciones)


kable(
  tabla_ordenes,
  caption = "**Órdenes de Diferenciación Requeridas (ndiffs)**",
  col.names = c("Serie", "Orden (d)"), 
  digits = 0
)
```

Entonces basta con la diferencia de orden 1, para que nuestras series temporales sean Estacionarias:

```{r, echo=FALSE, warning=FALSE}
so2_ts |> 

  filter(ESTACION != "Guamani") |> 
  mutate(SO2_diff=difference(SO2)) |> 
  autoplot(SO2_diff) + 
  labs(title = "Serie diferenciada: \n Cantidad de SO2 por estación (Guamani Excluido)") + 
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) + 
  theme(legend.position = "none")
```

Ahora, con nuestras series transformadas a series estacionarias, la información del PACF será de interés.

##### PACF

```{r, echo=FALSE}
so2_ts |> 
  PACF(SO2) |> 
  autoplot() + 
  labs(title = "ACF de cantidad de SO2 por estación") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")

```

Por tanto, veamos los valores de la auto-correlación parcial con los distintos lags

```{r , echo=FALSE}
pacf_resultados_completos <- so2_ts |> 
  PACF(SO2, lag_max = 200) |> 
  as_tibble()


tabla_wide <- pacf_resultados_completos |>
  mutate(lag_num = as.numeric(gsub("D", "", lag))) |>
  
  filter(lag_num <= 10) |>
  select(-lag_num) |> 
 
  pivot_wider(
    names_from = lag, 
    values_from = pacf
  )


tabla_PACF <- gt(tabla_wide) |>
  tab_header(
    title = "SO2 - Valores PACF por Lag"
  ) |>
  fmt_number(
    columns = -ESTACION, 
    decimals = 4
  )

# Mostrar la tabla
tabla_PACF

```

Notamos entonces que existe una auto-correlación parcial significativa con el lag 1.

***Gracias a todo lo visto antes, el modelo se podría explicar como un AR(1)***

#### División de los datos

```{r, include=FALSE}
separar_datos_entrenamiento_prueba <- function(tsibble_datos, prop_entrenamiento = 0.8) {

  if (!inherits(tsibble_datos, "tbl_ts")) {
    stop("La entrada debe ser un objeto tsibble.")
  }

  datos_entrenamiento <- tsibble_datos |>
    group_by(ESTACION) |> 
    slice_head(prop = prop_entrenamiento) |> 
    ungroup()

  datos_prueba <- tsibble_datos |>
    group_by(ESTACION) |> 
    slice_tail(prop = 1 - prop_entrenamiento) |> 
    ungroup()

  return(list(
    entrenamiento = datos_entrenamiento,
    prueba = datos_prueba
  ))
}

datos_separados <- separar_datos_entrenamiento_prueba(so2_ts)
```

```         
```

### Modelado

Dado que el análisis exploratorio reveló comportamientos heterogéneos entre las estaciones de monitoreo, especialmente en lo referente a la estacionariedad (Test KPSS), se ha optado por especificar modelos distintos que se ajusten a la estructura particular de cada serie.

#### **A. Estación Guamaní (Modelo Estacionario)**

Para la estación Guamaní, las pruebas de raíz unitaria indicaron que la serie es estacionaria en niveles.

-   **Diferenciación (**$d=0, D=0$): El test KPSS no rechazó la hipótesis nula de estacionariedad, por lo que no se aplica diferenciación.

-   **Componente Autoregresivo (**$p=1$): El PACF muestra un corte significativo en el primer retardo ($\phi_1 \approx 0.61$), sugiriendo un proceso AR(1).

-   **Estacionalidad:** Al no presentar una necesidad clara de diferenciación ni patrones estacionales visuales fuertes, se propone un modelo parsimonioso sin componente estacional complejo.

$\text{Modelo Propuesto: } ARIMA(1,0,0)$

#### **B. Resto de Estaciones (Belisario, Carapungo, etc.)**

Para el resto de las estaciones, se identificó un comportamiento no estacionario y una estructura de correlación similar.

-   **Diferenciación (**$d=1$): Necesaria para estabilizar la media, conforme a los resultados del test KPSS y el análisis visual.

-   **Componente Autoregresivo (**$p=1$): Se observa una alta correlación parcial en el lag 1 seguida de un corte abrupto, característico de un AR(1).

-   **Componente Estacional (**$P=1$): Se incorpora un término autoregresivo estacional de periodo semanal ($s=7$). Aunque la señal visual en el PACF es débil, se justifica teóricamente debido al ciclo de actividad humana (días laborables vs. fin de semana) que gobierna las emisiones de $SO_2$.

$\text{Modelo Propuesto: } ARIMA(1,1,0)(1,0,0)[7]$

```{r}
# --- PASO 1: Modelos Manuales (Criterio del Investigador) ---

# A. Para Guamaní (Estacionaria): ARIMA(1,0,0)
fit_manual_guamani <- datos_separados$entrenamiento |>
  filter(ESTACION == "Guamani") |>
  model(
    Modelo_Propuesto = ARIMA(SO2 ~ pdq(1, 0, 0) + PDQ(0, 0, 0))
  )

# B. Para el Resto (No Estacionarias): SARIMA(1,1,0)(1,0,0)[7]
fit_manual_resto <- datos_separados$entrenamiento |>
  filter(ESTACION != "Guamani") |>
  model(
    Modelo_Propuesto = ARIMA(SO2 ~ pdq(1, 0, 0) + PDQ(1, 0, 0, period = 7))
  )


fit_automatico <- datos_separados$entrenamiento |>
  model(
    Modelo_Automatico = ARIMA(SO2)
  )

#  Extracción de AICc y BIC para comparar ---

glance_manual_guamani <- glance(fit_manual_guamani)
glance_manual_resto   <- glance(fit_manual_resto)
glance_automatico     <- glance(fit_automatico)


tabla_comparativa <- bind_rows(glance_manual_guamani, glance_manual_resto) |>
  bind_rows(glance_automatico) |>
  select(ESTACION, MODELO = .model, AIC, AICc, BIC) |>
  arrange(ESTACION, AICc)

kable(tabla_comparativa, 
      caption = "Comparación de Ajuste: Modelo Propuesto vs. Automático (AICc)",
      digits = 2)
```

La serie de Belisario Diferenciada, cumple que:

-   el ACF decae exponencialmente

-   Hay un pico significativo en el las p=1, pero nínguno más allá del lag p, sin considerar la estacionalidad de cada semana

La serie de Carapungo Diferenciada, cumple que:

-   el ACF decae exponencialmente

-   Hay un pico significativo en el las p=1, pero nínguno más allá del lag p, sin considerar la estacionalidad de cada semana

Por tanto, se puede decir que los datos para Belisario y Carapungo siguen un ARIMA(p,d,0), pero por la estacionalidad de los datos, que hace sentido que pasando 7 días, se repita el comportamiento, el mejor modelo que podría ajustarse sea SARIMA.\
\
Analisis general, tomando d=1, P=1,D=0,Q=0,S=7.

```{r, echo=FALSE, warning=FALSE}
#Parametros tras el analisis
grid_params <- expand.grid(
  p = 0:3, d = 1, q = 0:3,       # Parte no estacional
  P = 1, D = 0, Q = 0,     # Parte estacional
  S = 7                          # Periodo 
)
#Modelar y tomar los mejores 2 dado AIC
modelado_top2 <- function(datos, est, params) {
  resultados <- list() 
  
  for(i in 1:nrow(params)) {
    fit <- try(arima(datos, 
                     order = c(params$p[i], params$d[i], params$q[i]),
                     seasonal = list(order = c(params$P[i], params$D[i], params$Q[i]),period = params$S[i]),), 
               silent = TRUE)
    
    if(!inherits(fit, "try-error")) {
      resultados[[i]] <- tibble(
        Estacion = est,
        Orden = paste0("(",params$p[i],",",params$d[i],",",params$q[i],")",
                       "(",params$P[i],",",params$D[i],",",params$Q[i],")[",params$S[i],"]"),
        AIC = fit$aic,
        BIC = BIC(fit) 
      )
    }
  }
  
  
  bind_rows(resultados) |> 
    arrange(AIC) |> #Escoger AIC o BIC (Similar)
    slice_head(n = 2)
}

mejores_modelos_final <- tibble() 
estaciones <- unique(so2_ts$ESTACION)
for(est in estaciones) {
  serie_vec <- so2_ts |> filter(ESTACION == est) |> pull(SO2)
  top_estacion <- modelado_top2(serie_vec, est, grid_params)
  mejores_modelos_final <- bind_rows(mejores_modelos_final, top_estacion)
}
mejores_modelos_final <- mejores_modelos_final |> distinct()
print(mejores_modelos_final)

```

```{r, echo=FALSE, warning=FALSE}

#Estimaciones del mejor modelo de cada estacion
ganadores <- mejores_modelos_final |>
  group_by(Estacion) |>
  slice_min(AIC, n = 1) |>
  distinct(Estacion, .keep_all = TRUE) |> 
  ungroup()


ajustar_mle_forecast <- function(estacion, orden_str, datos_ts) {
  
  nums <- as.numeric(unlist(str_extract_all(orden_str, "\\d+")))
  serie_vec <- datos_ts |> 
    filter(ESTACION == estacion) |> 
    pull(SO2) |> 
    ts(frequency = 7) 
  
  # Ajuste del modelo forzando parámetros y MLE
  fit <- Arima(serie_vec,
               order = c(nums[1], nums[2], nums[3]),
               seasonal = list(order = c(nums[4], nums[5], nums[6]), period = nums[7]),
               include.mean = TRUE, 
               method = "ML")
  
  return(list(modelo = fit, estacion = estacion, orden = orden_str))
}

resultados_mle <- list()

for(i in 1:nrow(ganadores)) {
  resultados_mle[[ganadores$Estacion[i]]] <- ajustar_mle_forecast(
    ganadores$Estacion[i], 
    ganadores$Orden[i], 
    so2_ts
  )
}

# Ver resultados por estacion Ej:Los Chillos
print(summary(resultados_mle[["Los Chillos"]]$modelo))
print(coeftest(resultados_mle[["Los Chillos"]]$modelo))
```
