---
title: "PROYECTO 1 ST"
format: html
editor: visual
---

# Series Temporales: Proyecto B1

```{r, echo=FALSE, include=FALSE}
#Librerías
library(tsibble)
library(dplyr)
library(lubridate)
library(fpp3)
library(tidyverse)
library(leaflet)
library(zoo)
library(fable)
library(imputeTS)
library(ggplot2)
library(tidyr)
library(stringr)
library(patchwork)
library(feasts)
library(knitr)
library(here)
library(astsa)
library(stringr)
library(lmtest)
library(forecast)
#install.packages("astsa",dependencies=TRUE)
#Editar para encontrar la base de datos

ruta<-here("maate_concentracionso2_2021diciembre.csv")
```

```{r, echo=FALSE}
datos_so2 <- read.csv(ruta,sep=";",dec = ",")
head(datos_so2)
datos_so2 <- datos_so2 |>
  mutate(FECHA = make_date(ANIO, CODMES, DIA)) |>
  mutate(SO2 = stringr::str_replace(SO2, ",", ".")) |> # Reemplaza , por .
  mutate(SO2 = as.numeric(SO2)) 

so2_diario <- datos_so2 |> 
  filter(!is.na(SO2))
so2_diario
```

Tomaremos como nuestro índice temporal a la variable *FECHA.*

Ahora, el estudio se realizará en la provincia de Pichincha, entonces, las series temporales consideradas se basarán en cada estación de cada cantón de la ciudad de Quito. Como primera instancia, se realizará un análisis de características de seis estaciones de interés; a saber, Belisario, Carapungo, Cotocollao, Tumbaco, (las dos que faltan). En conjunto, estas estaciones muestran un gran contraste en la tipología de exposición y las fuentes de emisión, puesto que algunas de ellas enfrentan diariamente una exposición y emisión alta de SO2 por la presencia de actividades humanas a comparación de otras.

```{r warning=FALSE, include=FALSE}
vector_estaciones <- c("Belisario", "Carapungo", "Cotocollao", "Tumbaco","Los Chillos","Guamani")

so2_ts <- so2_diario |> 
    filter(PROV == "Pichincha", ESTACION %in% vector_estaciones) |> 
    select(FECHA, ESTACION, SO2) |> 
    as_tsibble(index = FECHA, key = ESTACION) |> 
    fill_gaps() |> 
    mutate(SO2 = imputeTS::na_seadec(SO2, algorithm = "interpolation", 
                                     find_frequency = TRUE))
so2_ts
```

```{r, echo=FALSE}
serie_estaciones <- function(so2_diario, vector_estaciones) {
  
  so2_por_estaciones <- list()
  for(i in 1:length(vector_estaciones)){
    so2_por_estaciones[[i]] <- so2_ts |> 
      filter(ESTACION == vector_estaciones[i])
  }
  
  so2_por_estaciones
}

serie <- serie_estaciones(so2_diario, vector_estaciones)
serie
```

Con la frecuencia diaria, pues, el SO2 al ser una sustancia muy volatil, es de interés saber los días que se alcanzan los máximos durante el año. Además que el SO2 suele estar ligado a la actividad humana, entonces, la medición diaria del SO2 tiene la capacidad de mostrar patrones cruciales. (REFERENCIA)

### Diversidad de las series de interés

#### Tendencia

```{r, echo=FALSE}

so2_ts |> 
  autoplot(SO2) +
  labs(title = "Concentración de SO2 por Estación", x = "Tiempo", y = "SO2") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")

```

#### Estacionalidad

```{r, echo=FALSE, warning=FALSE}

so2_ts |> 
  gg_season(SO2, labels="both") +
  labs(y="SO2 HG/m^3", x = "Tiempo",
       title = "Cantidad de SO2 en el aire por estaciones")

```

En el gráfico anterior se muestra que los primeros y últimos días de cada año, se da un efecto descendiente del SO2 en el aire, un patrón que como se explicó, se lo localiza por una frecuencia diaria.

#### Descomposición

El siguiente objetivo es ver el comportamiento de cada componente de la descomposición de ambas series.

```{r, echo=FALSE}
so2_ts |> 
  model(stl=STL(SO2)) |> 
  components() |> 
  autoplot() +
  labs(title = "Descomposición STL", x="Tiempo")
```

#### Estacionaridad

##### ACF

```{r, echo=FALSE}

so2_ts |> 
  ACF(SO2, lag_max = 200) |> 
  autoplot() + 
  labs(title = "ACF de cantidad de SO2 por estación") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")

```

(MODIFICAR) Los gráficos de la ACF, muestran que existe auto-correlación con lags pasados. Como por ejemplo el caso de Belisario, posee una alta auto-correlación hasta un lag cercano a 200, a diferencia de la cantidad de SO2 en Carapungo, que muestra una correlación más fuerte con los lag cercanos a 3.

Podemos ver en la siguiente tabla de valores del ACF para las dos series.

```{r, echo=FALSE, warning=FALSE}
library(gt)
library(htmltools)

acf_resultados_completos <- so2_ts |> 
  ACF(SO2, lag_max = 200) |> 
  as_tibble()

crear_tabla_gt_acf <- function(nombre_estacion) {
  resumen_estacion <- acf_resultados_completos |>
    filter(ESTACION == nombre_estacion) |>
    arrange(desc(abs(acf))) |>
    slice_head(n = 5) |> 
    select(Lag = lag, ACF = acf)
  gt(resumen_estacion) |>
    tab_header(
      title = paste("SO2 en", nombre_estacion)
    ) |>
    fmt_number(
      columns = ACF, 
      decimals = 4
    ) |>
    tab_options(
      table.font.size = "small",
      heading.title.font.size = "medium"
    )
}
lista_de_tablas_gt <- lapply(vector_estaciones, crear_tabla_gt_acf)


lista_de_tablas_html <- lapply(lista_de_tablas_gt, as.tags)

div(
  style = "display: grid; grid-template-columns: 1fr 1fr; gap: 20px;",
  lista_de_tablas_html[[1]], # Belisario
  lista_de_tablas_html[[2]], # Carapungo
  lista_de_tablas_html[[3]], # Cotocollao
  lista_de_tablas_html[[4]]  # Tumbaco
)
```

Pero, es posible obtener un mejor acercamiento a la dependencia de la serie con los LAGS, pero primero se debe verificar si las series son Estacionarias o sino convertirlas con alguna transformación.

###### Método del ROLLMEAN

```{r, echo=FALSE, warning=FALSE}
so2_ts |> 
  mutate(mm=rollmean(SO2, k=5, fill = NA)) |> 
  autoplot(SO2) + 
  geom_line(aes(y=mm), colour="#D55E00") +
  labs(title = "Cantidad de SO2 por estación y la media puntual a lo largo del tiempo") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none") +
  guides(color = "none") +
  scale_color_manual(values = rep("black", length(vector_estaciones)))
```

A simple vista, parecen ser ambas series no estacionarias, pues, en los años del 2005 al 2006, las medias presentan picos muy altos, además que existe también una homocedasticidad.

Probemos el Test de KPSS para determinar si son o no estacionarias:

```{r, echo=FALSE}
test_kpss_todos <- so2_ts |> 
  features(SO2, unitroot_kpss)
tabla_kpss <- test_kpss_todos |> 
  filter(ESTACION %in% c("Belisario", "Carapungo", "Cotocollao","Tumbaco","Los Chillos", "Guamani"))

kable(
  tabla_kpss,
  caption = "Resultados de la Prueba KPSS", 
  col.names = c("Fuente", "Estadístico", "Valor P"),
  digits = 4
)                                 
```

En todos los casos, por el test KPSS, se rechaza la idea que las series sean estacionarias pues, el *p-value* es menor o igual a 0.01.

Entonces para ver realmente alguna dependencia de las series con algún LAG, por medio del PACF (además de luego poder aplicar métodos de modelado) , necesitamos que las series sean estacionarias. La forma más sencilla podría ser una simple diferenciación de orden m, para ellos KPSS, otorga el orden de diferenciación

```{r, echo=FALSE}

ordenes_diff <- so2_ts |> 
  features(SO2, unitroot_ndiffs)

tabla_ordenes <- ordenes_diff |> 
  filter(ESTACION %in% c("Belisario", "Carapungo", "Cotocollao","Tumbaco","Los Chillos", "Guamani"))


kable(
  tabla_ordenes,
  caption = "**Órdenes de Diferenciación Requeridas (ndiffs)**",
  col.names = c("Serie", "Orden (d)"), 
  digits = 0
)
```

Entonces basta con la diferencia de orden 1, para que nuestras series temporales sean Estacionarias:

```{r, echo=FALSE, warning=FALSE}
so2_ts |> 
  mutate(SO2_diff=difference(SO2)) |> 
  autoplot(SO2_diff) + 
  labs(title = "Serie diferenciada: \n Cantidad de SO2 por estación") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")
```

Ahora, con nuestras series transformadas a series estacionarias, la información del PACF será de interés.

##### PACF

```{r, echo=FALSE}
so2_ts |> 
  PACF(SO2) |> 
  autoplot() + 
  labs(title = "PACF de cantidad de SO2 por estación") +
  facet_wrap(vars(ESTACION), scales = "free_y", ncol = 2) +
  theme(legend.position = "none")

```

Por tanto, veamos los valores de la auto-correlación parcial con los distintos lags

```{r , echo=FALSE}
library(gt)
library(htmltools)
pacf_resultados <- so2_ts |>
  PACF(SO2, lag_max = 200) |>
  as_tibble()
crear_tabla_gt_pacf <- function(nombre_estacion) {
  resumen_estacion <- pacf_resultados |>
    filter(ESTACION == nombre_estacion) |>
    arrange(desc(abs(pacf))) |>
    slice_head(n = 5) |> 
    select(Lag = lag, PACF = pacf) 
  gt(resumen_estacion) |>
    tab_header(
      title = paste("SO2 en", nombre_estacion) 
    ) |>
    fmt_number(
      columns = PACF, 
      decimals = 4
    ) |>
    tab_options(
      table.font.size = "small",
      heading.title.font.size = "medium"
    )
}

lista_de_tablas_gt_pacf <- lapply(vector_estaciones, crear_tabla_gt_pacf)

lista_de_tablas_html_pacf <- lapply(lista_de_tablas_gt_pacf, as.tags)


div(
  style = "display: grid; grid-template-columns: 1fr 1fr; gap: 20px;",
  lista_de_tablas_html_pacf[[1]], # Belisario
  lista_de_tablas_html_pacf[[2]], # Carapungo
  lista_de_tablas_html_pacf[[3]], # Cotocollao
  lista_de_tablas_html_pacf[[4]]  # Tumbaco
)

```

Notamos entonces que existe una auto-correlación parcial significativa con el lag 1.

***####Gracias a todo lo visto antes, el modelo se podría explicar como un AR(1)***

#### División de los datos

**Serie Belisario**

```{r}
s1d_e<-serie1_diff%>%slice_head(prop = 0.8)
s1d_p<-serie1_diff%>%slice_head(prop = 0.2)
```

**Serie Carapungo**

```{r}
s2d_e<-serie2_diff%>%slice_head(prop = 0.8)
s2d_p<-serie2_diff%>%slice_head(prop = 0.2)
```

### Modelado

Como se discutió anteriormente, el análisis de la Función de Autocorrelación Parcial (PACF) de las series diferenciadas sugirió un modelo Autorregresivo de orden 1 (AR(1)). A continuación, se realizará el análisis complementario de la **Función de Autocorrelación (ACF)** para determinar el orden del componente de Media Móvil (MA).

```{r, echo=FALSE, warning=FALSE}
g7<-serie1_diff%>%fill_gaps()%>%ACF(SO2, lag_max = 200)%>%autoplot()+labs(title = "Cantidad de SO2 en Belisario Diferenciada")

g8<-serie2_diff%>%fill_gaps()%>%ACF(SO2, lag_max = 200)%>%autoplot()+labs(title = "Cantidad de SO2 en Carapungo Diferenciada")

 g7/g8 
```

```{r, echo=FALSE}
g5/g6
```

La serie de Belisario Diferenciada, cumple que:

-   el ACF decae exponencialmente

-   Hay un pico significativo en el las p=1, pero nínguno más allá del lag p, sin considerar la estacionalidad de cada semana

La serie de Carapungo Diferenciada, cumple que:

-   el ACF decae exponencialmente

-   Hay un pico significativo en el las p=1, pero nínguno más allá del lag p, sin considerar la estacionalidad de cada semana

Por tanto, se puede decir que los datos para Belisario y Carapungo siguen un ARIMA(p,d,0), pero por la estacionalidad de los datos, que hace sentido que pasando 7 días, se repita el comportamiento, el mejor modelo que podría ajustarse sea SARIMA

```{r, echo=FALSE, warning=FALSE}
#Parametros tras el analisis
grid_params <- expand.grid(
  p = 0:3, d = 1, q = 0:3,       # Parte no estacional
  P = 1, D = 0, Q = 0,     # Parte estacional
  S = 7                          # Periodo 
)
#Modelar y tomar los mejores 2 dado AIC
modelado_top2 <- function(datos, est, params) {
  resultados <- list() 
  
  for(i in 1:nrow(params)) {
    fit <- try(arima(datos, 
                     order = c(params$p[i], params$d[i], params$q[i]),
                     seasonal = list(order = c(params$P[i], params$D[i], params$Q[i]                      ),period = params$S[i]),), 
               silent = TRUE)
    
    if(!inherits(fit, "try-error")) {
      resultados[[i]] <- tibble(
        Estacion = est,
        Orden = paste0("(",params$p[i],",",params$d[i],",",params$q[i],")",
                       "(",params$P[i],",",params$D[i],",",params$Q[i],")[",params$S[i],"]"),
        AIC = fit$aic,
        BIC = BIC(fit) 
      )
    }
  }
  
  
  bind_rows(resultados) |> 
    arrange(AIC) |> #Escoger AIC o BIC (Similar)
    slice_head(n = 2)
}

mejores_modelos_final <- tibble() 
estaciones <- unique(so2_ts$ESTACION)
for(est in estaciones) {
  serie_vec <- so2_ts |> filter(ESTACION == est) |> pull(SO2)
  top_estacion <- modelado_top2(serie_vec, est, grid_params)
  mejores_modelos_final <- bind_rows(mejores_modelos_final, top_estacion)
}
mejores_modelos_final <- mejores_modelos_final |> distinct()
print(mejores_modelos_final)





```

```{r, echo=FALSE, warning=FALSE}

#Estimaciones del mejor modelo de cada estacion
ganadores <- mejores_modelos_final |>
  group_by(Estacion) |>
  slice_min(AIC, n = 1) |>
  distinct(Estacion, .keep_all = TRUE) |> 
  ungroup()


ajustar_mle_forecast <- function(estacion, orden_str, datos_ts) {
  
  nums <- as.numeric(unlist(str_extract_all(orden_str, "\\d+")))
  serie_vec <- datos_ts |> 
    filter(ESTACION == estacion) |> 
    pull(SO2) |> 
    ts(frequency = 7) 
  
  # Ajuste del modelo forzando parámetros y MLE
  fit <- Arima(serie_vec,
               order = c(nums[1], nums[2], nums[3]),
               seasonal = list(order = c(nums[4], nums[5], nums[6]), period = nums[7]),
               include.mean = TRUE, 
               method = "ML")
  
  return(list(modelo = fit, estacion = estacion, orden = orden_str))
}

resultados_mle <- list()

for(i in 1:nrow(ganadores)) {
  resultados_mle[[ganadores$Estacion[i]]] <- ajustar_mle_forecast(
    ganadores$Estacion[i], 
    ganadores$Orden[i], 
    so2_ts
  )
}

# Ver resultados por estacion Ej:Los Chillos
print(summary(resultados_mle[["Los Chillos"]]$modelo))
print(coeftest(resultados_mle[["Los Chillos"]]$modelo))
```
